{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_Embeddings_in_Action_Word2Vec.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitinsharma006/data_science/blob/master/Word%20Embeddings/Word_Embeddings_in_Action_Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWWH8Gvgd09_"
      },
      "source": [
        "# Word Embeddings in Action - Word2Vec\n",
        "\n",
        "Steps to follow:\n",
        "\n",
        "1. Get data\n",
        "2. Clean text data\n",
        "3. Tokenization\n",
        "4. Prepare vocabulary\n",
        "5. Download pre-trained embeddings\n",
        "6. Get word vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPnpxm2s7Zty"
      },
      "source": [
        "# import required libraries\n",
        "import numpy as np\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7ubotsYxoTi"
      },
      "source": [
        "# 1. Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgII8L1Xd0-Q"
      },
      "source": [
        "#input text\n",
        "text=['Building some bots for Wikipedia.',\n",
        "      'Wikipedia is flooded with information.',\n",
        "      'There is an app for everthing.']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndLOg1M3xw5u"
      },
      "source": [
        "# 2. Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DpVJTY4uzCM"
      },
      "source": [
        "# cleaning\n",
        "import re\n",
        "\n",
        "def clean(text):\n",
        "  #lower case\n",
        "  text=text.lower()\n",
        "  \n",
        "  #remove punctuations\n",
        "  text=re.sub('[^a-zA-Z]',\" \",text)\n",
        "  \n",
        "  return text"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W8UmlIZu3Bq"
      },
      "source": [
        "#call the clean function\n",
        "cleaned_text=[]\n",
        "\n",
        "for i in text:\n",
        "  cleaned_text.append(clean(i))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSslu0ObyCxo"
      },
      "source": [
        "# 3. Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF8vhjlDu4Y-",
        "outputId": "e355365b-58db-4aa9-b64c-6546591ead3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#tokenize the text\n",
        "tokens=[]\n",
        "\n",
        "for i in cleaned_text:\n",
        "  tokens.append(i.split())\n",
        "\n",
        "print(tokens)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['building', 'some', 'bots', 'for', 'wikipedia'], ['wikipedia', 'is', 'flooded', 'with', 'information'], ['there', 'is', 'an', 'app', 'for', 'everthing']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBcFBdRFyGzQ"
      },
      "source": [
        "# 4. Vocabulary Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNd7ic_WvFqO",
        "outputId": "1cc95b18-ea64-4a18-9fd5-1c6067ea1145",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#construct vocabulary\n",
        "vocab=[]\n",
        "\n",
        "for i in tokens:\n",
        "  for j in i:\n",
        "    if j not in vocab:\n",
        "      vocab.append(j)\n",
        "\n",
        "#remove duplicate token\n",
        "vocab = list(set(vocab))\n",
        "\n",
        "print(vocab)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['an', 'there', 'with', 'is', 'flooded', 'for', 'some', 'bots', 'app', 'information', 'everthing', 'building', 'wikipedia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMc9TTmSyO67"
      },
      "source": [
        "#5. Feature Representation (word2vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Fpt6-ned1AI"
      },
      "source": [
        "### Download Google's pre-trained Word2Vec\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQNZ7Exh3jky",
        "outputId": "3b4f1583-ca8a-409f-bc10-a22b011027b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# download and extract word2vec embeddings \n",
        "! wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
        "! gunzip GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-09 10:43:18--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.202.152\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.202.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  61.5MB/s    in 24s     \n",
            "\n",
            "2022-03-09 10:43:42 (64.7 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoHGUSuId1AO"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# path of the downloaded model\n",
        "filename = 'GoogleNews-vectors-negative300.bin'\n",
        "\n",
        "# load into gensim\n",
        "w2vec = KeyedVectors.load_word2vec_format(filename, binary=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5WyFsVHd1Aj"
      },
      "source": [
        "Once you have executed the above code, your word2vec embeddings are finally installed and loaded. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "assnsO6Ld1Ap"
      },
      "source": [
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "Please note that the length of every vector of the pre-trained word2vec embeddings is 300.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV0yy-P0sPKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f3854b1-37a4-4431-8abb-2a2baf6070f1"
      },
      "source": [
        "# empty array of shape (no. of tokens X 300) to store word2vec features\n",
        "wordvec_array = np.zeros((len(vocab), 300))\n",
        "\n",
        "for i,j in enumerate(vocab):\n",
        "  wordvec_array[i,:] = w2vec.wv.word_vec(j)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpsWAoaap5AA",
        "outputId": "e89ba9dc-dd0f-466b-c2e5-76dca9a21b27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "wordvec_array"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.12597656,  0.19042969,  0.06982422, ...,  0.0612793 ,\n",
              "         0.17285156, -0.07861328],\n",
              "       [ 0.09423828, -0.02282715,  0.05224609, ..., -0.046875  ,\n",
              "         0.16113281, -0.19921875],\n",
              "       [-0.02490234,  0.02197266, -0.03540039, ...,  0.01080322,\n",
              "        -0.01879883, -0.06884766],\n",
              "       ...,\n",
              "       [ 0.22460938, -0.06542969, -0.08544922, ..., -0.14257812,\n",
              "         0.04394531,  0.03271484],\n",
              "       [-0.00976562,  0.02856445,  0.05419922, ..., -0.01300049,\n",
              "         0.11621094,  0.02819824],\n",
              "       [ 0.21875   , -0.12207031, -0.00296021, ..., -0.35351562,\n",
              "        -0.25195312, -0.11621094]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRbv0MVl_hG1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}