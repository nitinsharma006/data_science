{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN and its variants in PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "f1QO2V5C1q0c",
        "iPD3sYkO2C8k",
        "8cN7_48hWIGA",
        "qWU2ZDir2q0j"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitinsharma006/data_science/blob/master/Neural%20Networks/RNN_and_its_variants_in_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTMDkffWSky-"
      },
      "source": [
        "\n",
        "# Objective\n",
        "\n",
        "The objective of notebook is to build a model to automatically predict tags for a given a StackExchange question by using the text of the question in PyTorch.\n",
        "![alt text](https://cdn.sstatic.net/Sites/stackoverflow/company/img/logos/se/se-logo.svg?v=d29f0785ebb7)\n",
        "\n",
        "__Dataset Specs__: Over 85,000 questions and over 1300 unique tags\n",
        "\n",
        "[Download Link](https://www.kaggle.com/stackoverflow/statsquestions#Questions.csv)\n",
        "\n",
        "\n",
        "# Steps To Follow\n",
        "\n",
        "\n",
        "1. Load Data and Import Libraries\n",
        "\n",
        "2. Dataset Preparation\n",
        "\n",
        "      2.1 Merge Tags with Questions\n",
        "\n",
        "      2.2 Filter Questions with respect to Top-10 Tags\n",
        "      \n",
        "3. Text Preprocessing\n",
        "\n",
        "      3.1 Text Cleaning\n",
        "\n",
        "      3.2 Text Representation\n",
        "\n",
        "4. Model Building\n",
        "\n",
        "      4.1 Model Architecture\n",
        "\n",
        "      4.2 Model Training\n",
        "\n",
        "5. Model Evaluation\n",
        "\n",
        "      5.1 Check Performance\n",
        "\n",
        "      5.2 Show Inference\n",
        "\n",
        "6. Model Building for LSTM\n",
        "\n",
        "7. Model Evaluation for LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48YGFqrAy6zf"
      },
      "source": [
        "# 1. Load Data and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJvSO7bDONu4",
        "outputId": "bcd922c8-5b1b-4d32-85d6-f7f18e05905f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZiyIx06RTdD",
        "outputId": "9c52fbfd-fbc6-4e78-fe62-dbcf5cd84181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# extract data from the ZIP file\n",
        "!unzip '/content/drive/My Drive/statsquestions.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/statsquestions.zip\n",
            "  inflating: Answers.csv             \n",
            "  inflating: Questions.csv           \n",
            "  inflating: Tags.csv                \n",
            "  inflating: database.sqlite         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM2S4yCsR7i6"
      },
      "source": [
        "#string matching\n",
        "import re \n",
        "\n",
        "#reading files\n",
        "import pandas as pd\n",
        "## change display width of pandas dataframe\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "\n",
        "#array processing\n",
        "import numpy as np\n",
        "\n",
        "#handling html data\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#visualization\n",
        "import matplotlib.pyplot as plt  \n",
        "\n",
        "#for metrics\n",
        "from sklearn import metrics\n",
        "\n",
        "#for seed\n",
        "import random\n",
        "\n",
        "# to one hot encode labels\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "#defining tensors\n",
        "import torch\n",
        "\n",
        "#layers\n",
        "from torch import nn\n",
        "\n",
        "#layers and wrappers\n",
        "from torch.nn import Sequential, Linear,  ReLU, Sigmoid, Dropout, BCELoss, Embedding, RNN, LSTM\n",
        "\n",
        "#handling text data\n",
        "from torchtext import data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD8BvEEFR_40"
      },
      "source": [
        "# load the stackoverflow questions dataset\n",
        "questions_df = pd.read_csv('Questions.csv',encoding='latin-1')\n",
        "\n",
        "# load the tags dataset\n",
        "tags_df = pd.read_csv('Tags.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE88kY9WR_-n",
        "outputId": "94da7aa0-0379-4966-d1f6-5307c695b8ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "#Glance at the first 5 rows\n",
        "questions_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>OwnerUserId</th>\n",
              "      <th>CreationDate</th>\n",
              "      <th>Score</th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2010-07-19T19:14:44Z</td>\n",
              "      <td>272</td>\n",
              "      <td>The Two Cultures: statistics vs. machine learning?</td>\n",
              "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=\"http://anyall.org/\"&gt;Brendan O'Connor&lt;/a&gt; entitled &lt;a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\"&gt;\"Statistics vs. Mach...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>59.0</td>\n",
              "      <td>2010-07-19T19:24:36Z</td>\n",
              "      <td>4</td>\n",
              "      <td>Forecasting demographic census</td>\n",
              "      <td>&lt;p&gt;What are some of the ways to forecast demographic census with some validation and calibration techniques?&lt;/p&gt;\\n\\n&lt;p&gt;Some of the concerns:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Census blocks vary in sizes as rural\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>66.0</td>\n",
              "      <td>2010-07-19T19:25:39Z</td>\n",
              "      <td>208</td>\n",
              "      <td>Bayesian and frequentist reasoning in plain English</td>\n",
              "      <td>&lt;p&gt;How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?&lt;/p&gt;\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2010-07-19T19:28:44Z</td>\n",
              "      <td>138</td>\n",
              "      <td>What is the meaning of p values and t values in statistical tests?</td>\n",
              "      <td>&lt;p&gt;After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2010-07-19T19:31:47Z</td>\n",
              "      <td>58</td>\n",
              "      <td>Examples for teaching: Correlation does not mean causation</td>\n",
              "      <td>&lt;p&gt;There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;number of storks and birth ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                                                                                                                                                                                     Body\n",
              "0   6  ...  <p>Last year, I read a blog post from <a href=\"http://anyall.org/\">Brendan O'Connor</a> entitled <a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\">\"Statistics vs. Mach...\n",
              "1  21  ...  <p>What are some of the ways to forecast demographic census with some validation and calibration techniques?</p>\\n\\n<p>Some of the concerns:</p>\\n\\n<ul>\\n<li>Census blocks vary in sizes as rural\\n...\n",
              "2  22  ...                                                                               <p>How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?</p>\\n\n",
              "3  31  ...  <p>After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....\n",
              "4  36  ...  <p>There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:</p>\\n\\n<ol>\\n<li>number of storks and birth ...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxvK_9YFG2M1",
        "outputId": "d4b03840-5bf7-49ae-9df9-87844587890d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#shape of the dataset\n",
        "questions_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(85085, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7wSglDJSGWf",
        "outputId": "17539cf5-237b-4276-f5bf-391dc54e9b62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "#Take a glance at first 5 rows\n",
        "tags_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>bayesian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>prior</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>elicitation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>distributions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>normality</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id            Tag\n",
              "0   1       bayesian\n",
              "1   1          prior\n",
              "2   1    elicitation\n",
              "3   2  distributions\n",
              "4   2      normality"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz1-htTsSGM8",
        "outputId": "e211ec41-127f-4eb6-f5ba-2ed0fe39a42f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# No. of unique tags\n",
        "len(tags_df['Tag'].unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1315"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nQjFYQtTNH6"
      },
      "source": [
        "# 2. Dataset Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--FBzpS7y2t7"
      },
      "source": [
        "## 2.1 Merge Tags with Questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKoRHljISb83"
      },
      "source": [
        "# remove \"-\" from the tags\n",
        "tags_df['Tag'] = tags_df['Tag'].apply(lambda x:re.sub(\"-\",\" \",x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWQyeoa4ScDz",
        "outputId": "3e177c0d-3c84-4079-f2bf-de49d988f04c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "# group tags Id wise\n",
        "tags_df = tags_df.groupby('Id').apply(lambda x:x['Tag'].values).reset_index(name='tags')\n",
        "tags_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[bayesian, prior, elicitation]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[distributions, normality]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[software, open source]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>[distributions, statistical significance]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>[machine learning]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id                                       tags\n",
              "0   1             [bayesian, prior, elicitation]\n",
              "1   2                 [distributions, normality]\n",
              "2   3                    [software, open source]\n",
              "3   4  [distributions, statistical significance]\n",
              "4   6                         [machine learning]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB8sYYOrScCC"
      },
      "source": [
        "# merge tags and questions\n",
        "df = pd.merge(questions_df,tags_df,how='inner',on='Id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD7UD9yNSmk1"
      },
      "source": [
        "# fetch required columns\n",
        "df = df[['Id','Body','tags']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZEEr2B5eosb",
        "outputId": "b39aa80e-d8e0-4638-9ab6-d8a720a94588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "#first 5 rows\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Body</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=\"http://anyall.org/\"&gt;Brendan O'Connor&lt;/a&gt; entitled &lt;a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\"&gt;\"Statistics vs. Mach...</td>\n",
              "      <td>[machine learning]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>&lt;p&gt;What are some of the ways to forecast demographic census with some validation and calibration techniques?&lt;/p&gt;\\n\\n&lt;p&gt;Some of the concerns:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Census blocks vary in sizes as rural\\n...</td>\n",
              "      <td>[forecasting, population, census]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>&lt;p&gt;How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?&lt;/p&gt;\\n</td>\n",
              "      <td>[bayesian, frequentist]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31</td>\n",
              "      <td>&lt;p&gt;After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....</td>\n",
              "      <td>[hypothesis testing, t test, p value, interpretation, intuition]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36</td>\n",
              "      <td>&lt;p&gt;There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;number of storks and birth ...</td>\n",
              "      <td>[correlation, teaching]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                                              tags\n",
              "0   6  ...                                                [machine learning]\n",
              "1  21  ...                                 [forecasting, population, census]\n",
              "2  22  ...                                           [bayesian, frequentist]\n",
              "3  31  ...  [hypothesis testing, t test, p value, interpretation, intuition]\n",
              "4  36  ...                                           [correlation, teaching]\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J28FYn8xSmqM",
        "outputId": "5b4feef7-644d-4a60-b758-47d8d43bd6fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#shape of the dataset\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(85085, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1ZvB-t9TYKh"
      },
      "source": [
        "## 2.2 Filter Questions with respect to Top-10 Tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9XRjQ_wSmvh"
      },
      "source": [
        "# check occurence of each tag\n",
        "freq={}\n",
        "for i in df['tags']:\n",
        "  for j in i:\n",
        "    if j in freq.keys():\n",
        "      freq[j] = freq[j] + 1\n",
        "    else:\n",
        "      freq[j] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSVPSJnCSvUt"
      },
      "source": [
        "# sort the dictionary in descending order\n",
        "freq = dict(sorted(freq.items(), key=lambda x:x[1],reverse=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxDCpuGFSvhH",
        "outputId": "209a157d-b77b-45f3-ea6e-5fae88b0c8c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Top 10 most frequent tags\n",
        "common_tags = list(freq.keys())[:10]\n",
        "print(common_tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['r', 'regression', 'machine learning', 'time series', 'probability', 'hypothesis testing', 'self study', 'distributions', 'logistic', 'classification']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPC21Z5aTkB8"
      },
      "source": [
        "We will use only those questions/queries that are associated with the top 10 tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNksVjF6SvqS"
      },
      "source": [
        "#finding queries associated with common tags\n",
        "x=[]\n",
        "y=[]\n",
        "\n",
        "for i in range(len(df['tags'])):  \n",
        "\n",
        "  temp=[]\n",
        "  for j in df['tags'][i]:\n",
        "    if j in common_tags:\n",
        "      temp.append(j)\n",
        "  \n",
        "  #if common tags are more than 1\n",
        "  if(len(temp)>1):\n",
        "    x.append(df['Body'][i])\n",
        "    y.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck6w3DsfS82D",
        "outputId": "5d0ad330-9543-44d4-ab75-44909807bba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# number of questions left\n",
        "len(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tLZqaHQ-4Bz",
        "outputId": "20b776e0-d934-41b7-90d2-bbc6207e842e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#first 5 tags\n",
        "y[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['r', 'time series'],\n",
              " ['regression', 'distributions'],\n",
              " ['distributions', 'probability', 'hypothesis testing'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['r', 'regression', 'time series']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfTeISu8A3KT"
      },
      "source": [
        "#combining the labels by space\n",
        "y = [ \",\".join([str(j) for j in i ]) for i in y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnceeB6B_Tbd",
        "outputId": "d180f8f0-ae67-4caa-d1ff-4c0e617ec459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#labels after converting to string\n",
        "y[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['r,time series',\n",
              " 'regression,distributions',\n",
              " 'distributions,probability,hypothesis testing',\n",
              " 'hypothesis testing,self study',\n",
              " 'r,regression,time series']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYblHXWVgt_S"
      },
      "source": [
        "#save to dataframe\n",
        "dframe = pd.DataFrame({'query':x,'tags':y})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGUumAqqBpDa",
        "outputId": "7b0cb857-43ae-4cf5-cd9d-fe8450f84e06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "#first 5 rows\n",
        "dframe.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;p&gt;I recently started working for a tuberculosis clinic.  We meet periodically to discuss the number of TB cases we're currently treating, the number of tests administered, etc.  I'd like to start...</td>\n",
              "      <td>r,time series</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;p&gt;Am I looking for a better behaved distribution for the independent variable in question, or to reduce the effect of outliers, or something else?&lt;/p&gt;\\n</td>\n",
              "      <td>regression,distributions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;p&gt;There are many ways to measure how similar two probability distributions are.  Among methods which are popular (in different circles) are:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;p&gt;the Kolmogorov distance: the sup-d...</td>\n",
              "      <td>distributions,probability,hypothesis testing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;blockquote&gt;\\n  &lt;p&gt;A Lab has been asked to evaluate the claim that drinking water in a\\n  local restaurant has a lead concentration of 6 parts per billion\\n  (ppb). Repeated measurements follow a ...</td>\n",
              "      <td>hypothesis testing,self study</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;p&gt;How would we measure the predictive power of predictors in time series models. For e.g. in linear regression we have the magnitude and direction of the regression co-efficients and their p-valu...</td>\n",
              "      <td>r,regression,time series</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                     query                                          tags\n",
              "0  <p>I recently started working for a tuberculosis clinic.  We meet periodically to discuss the number of TB cases we're currently treating, the number of tests administered, etc.  I'd like to start...                                 r,time series\n",
              "1                                                <p>Am I looking for a better behaved distribution for the independent variable in question, or to reduce the effect of outliers, or something else?</p>\\n                      regression,distributions\n",
              "2  <p>There are many ways to measure how similar two probability distributions are.  Among methods which are popular (in different circles) are:</p>\\n\\n<ol>\\n<li><p>the Kolmogorov distance: the sup-d...  distributions,probability,hypothesis testing\n",
              "3  <blockquote>\\n  <p>A Lab has been asked to evaluate the claim that drinking water in a\\n  local restaurant has a lead concentration of 6 parts per billion\\n  (ppb). Repeated measurements follow a ...                 hypothesis testing,self study\n",
              "4  <p>How would we measure the predictive power of predictors in time series models. For e.g. in linear regression we have the magnitude and direction of the regression co-efficients and their p-valu...                      r,regression,time series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27-gnDPi60yg"
      },
      "source": [
        "#save to csv\n",
        "dframe.to_csv('stack.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5E3gvtJ0_eC"
      },
      "source": [
        "# 3. Text Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je87HHtQA6bO"
      },
      "source": [
        "Now, we will see the one of the most important library in PyTorch for handling text data - TorchText \n",
        "\n",
        "\n",
        "\n",
        "**TorchText** is a Natural Language Processing (NLP) library in PyTorch. This library contains the scripts for preprocessing text and data sources of few popular NLP datasets to test out the scripts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLmFzuLDCH0d"
      },
      "source": [
        "TorchText understands and operates on text data in terms of Field objects, and then Field objects are used to define the steps for text preprocessing\n",
        "\n",
        "There are 2 different types of field objects – **Field** and **LabelField**. \n",
        "\n",
        "* **Field**: Field object is used to specify preprocessing steps for each column in the dataset.\n",
        "\n",
        "* **LabelField**: LabelField object is a special case of Field object which is used only for the preprocessing of label column. \n",
        "\n",
        "Before we use Field, let us look at the different parameters of Field and what are they used for.\n",
        "\n",
        "**Parameters of Field**:\n",
        "\n",
        "* **Tokenize**: It specifies the way of tokenizing the sentence i.e. converting sentence to words. By default, it tokenizes with respect to spaces\n",
        "\n",
        "    * *Note*: It can be replaced by the preprocessing function as well.\n",
        "\n",
        "* **Lower**: It converts text to lowercase\n",
        "\n",
        "* **batch_first**: The first dimension of input and output is always batch size\n",
        "\n",
        "* **fix_length**: Maximum length of a sentence\n",
        "\n",
        "* **unk_token**: The string token used to represent OOV words. By default, this value is \"UNK\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM2i7pJ-1RLm"
      },
      "source": [
        "## 3.1 Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruV5khtmAiDU"
      },
      "source": [
        "def cleaner(text):\n",
        "\n",
        "  text = BeautifulSoup(text).get_text()\n",
        "  \n",
        "  # fetch alphabetic characters\n",
        "  text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
        "\n",
        "  # convert text to lower case\n",
        "  text = text.lower()\n",
        "\n",
        "  # split text into tokens to remove whitespaces\n",
        "  tokens = text.split()\n",
        "  \n",
        "  return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW0eN1UnrchO"
      },
      "source": [
        "#define field object for query\n",
        "max_len = 100\n",
        "TEXT = data.Field(tokenize=cleaner, batch_first=True, fix_length=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9PfZ04R8NkK"
      },
      "source": [
        "#define field object for label\n",
        "LABEL = data.LabelField(batch_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlM-zyeSEkEi"
      },
      "source": [
        "Next we are going to create a list of tuples where first value in every tuple contains a column name and second value is a field object. Furthermore we will arrange each tuple in the order of the columns of csv.\n",
        "\n",
        "Let us read only required columns – query and tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFoE3QDb8NfI"
      },
      "source": [
        "#define a list of tuple with field objects\n",
        "fields = [('query',TEXT),('tags', LABEL)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtZKZJZVEvCS"
      },
      "source": [
        "Now, we will load the custom dataset by defining the list of tuples. For this we use TabularDataset class\n",
        "\n",
        "**Parameters of TabularDataset**:\n",
        "\n",
        "* **path**: set the path of dataset\n",
        "\n",
        "* **format**: provide extension of file. \n",
        "    * **Note**: There are a limited number of extensions accepted by TorchText. Read the docs for more details\n",
        "\n",
        "* **fields**: give tuple of user defined fields which data would have\n",
        "\n",
        "* **skip_header**: boolean value; if set to true - ignores the first line of the data file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpOti-uNS8z_"
      },
      "source": [
        "#reading the dataset\n",
        "training_data = data.TabularDataset(path = 'stack.csv', format = 'csv', fields = fields, skip_header = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDXopkVgS9vy"
      },
      "source": [
        "Let see whether we can see examples of training data or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_U5N4OsS_ZI",
        "outputId": "1567d936-6b95-494c-cbc6-ff90a98543bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(training_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torchtext.data.dataset.TabularDataset object at 0x7fc080cb2e10>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hvxo_fyTKPE"
      },
      "source": [
        "Now, we will see how to print the examples of training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_imud4VBcGP",
        "outputId": "72ebf69d-1ad3-408f-9d92-bcf6dbc1cfc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#print preprocessed text\n",
        "print(vars(training_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'query': ['i', 'recently', 'started', 'working', 'for', 'a', 'tuberculosis', 'clinic', 'we', 'meet', 'periodically', 'to', 'discuss', 'the', 'number', 'of', 'tb', 'cases', 'we', 're', 'currently', 'treating', 'the', 'number', 'of', 'tests', 'administered', 'etc', 'i', 'd', 'like', 'to', 'start', 'modeling', 'these', 'counts', 'so', 'that', 'we', 're', 'not', 'just', 'guessing', 'whether', 'something', 'is', 'unusual', 'or', 'not', 'unfortunately', 'i', 've', 'had', 'very', 'little', 'training', 'in', 'time', 'series', 'and', 'most', 'of', 'my', 'exposure', 'has', 'been', 'to', 'models', 'for', 'very', 'continuous', 'data', 'stock', 'prices', 'or', 'very', 'large', 'numbers', 'of', 'counts', 'influenza', 'but', 'we', 'deal', 'with', 'cases', 'per', 'month', 'mean', 'median', 'var', 'which', 'are', 'distributed', 'like', 'this', 'image', 'lost', 'to', 'the', 'mists', 'of', 'time', 'image', 'eaten', 'by', 'a', 'grue', 'i', 've', 'found', 'a', 'few', 'articles', 'that', 'address', 'models', 'like', 'this', 'but', 'i', 'd', 'greatly', 'appreciate', 'hearing', 'suggestions', 'from', 'you', 'both', 'for', 'approaches', 'and', 'for', 'r', 'packages', 'that', 'i', 'could', 'use', 'to', 'implement', 'those', 'approaches', 'edit', 'mbq', 's', 'answer', 'has', 'forced', 'me', 'to', 'think', 'more', 'carefully', 'about', 'what', 'i', 'm', 'asking', 'here', 'i', 'got', 'too', 'hung', 'up', 'on', 'the', 'monthly', 'counts', 'and', 'lost', 'the', 'actual', 'focus', 'of', 'the', 'question', 'what', 'i', 'd', 'like', 'to', 'know', 'is', 'does', 'the', 'fairly', 'visible', 'decline', 'from', 'say', 'onward', 'reflect', 'a', 'downward', 'trend', 'in', 'the', 'overall', 'number', 'of', 'cases', 'it', 'looks', 'to', 'me', 'like', 'the', 'number', 'of', 'cases', 'monthly', 'from', 'reflects', 'a', 'stable', 'process', 'maybe', 'some', 'seasonality', 'but', 'overall', 'stable', 'from', 'through', 'the', 'present', 'it', 'looks', 'like', 'that', 'process', 'is', 'changing', 'the', 'overall', 'number', 'of', 'cases', 'is', 'declining', 'even', 'though', 'the', 'monthly', 'counts', 'might', 'wobble', 'up', 'and', 'down', 'due', 'to', 'randomness', 'and', 'seasonality', 'how', 'can', 'i', 'test', 'if', 'there', 's', 'a', 'real', 'change', 'in', 'the', 'process', 'and', 'if', 'i', 'can', 'identify', 'a', 'decline', 'how', 'could', 'i', 'use', 'that', 'trend', 'and', 'whatever', 'seasonality', 'there', 'might', 'be', 'to', 'estimate', 'the', 'number', 'of', 'cases', 'we', 'might', 'see', 'in', 'the', 'upcoming', 'months', 'whew', 'thanks', 'for', 'bearing', 'with', 'me'], 'tags': 'r,time series'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-QfgorLFIqF"
      },
      "source": [
        "As you can see here, the output is the cleaned text\n",
        "\n",
        "**Note**: *cleaning is done based on the field object defined* "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZIK_ogyFmQz"
      },
      "source": [
        "Split the dataset into training and validation now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40EZTlPsBVVA"
      },
      "source": [
        "train_data, valid_data = training_data.split(split_ratio=0.8, random_state = random.seed(32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0DyjPap1elw"
      },
      "source": [
        "## 3.2 Text Representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBOJBsu0F32-"
      },
      "source": [
        "The next step is to build the vocabulary for the text. For this we use *build_vocab* function on field object to construct a vocab object for the field\n",
        "\n",
        "Below are the important parameters for build_vocab:\n",
        "\n",
        "**Parameter**:\n",
        "\n",
        "* **Dataset object**: which is used to specify the data on which vocabulary has to be created\n",
        "\n",
        "* **min_freq**: Ignores the words in vocabulary which has frequency less than or equal to specified one and map it to unknown token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB5kUf-g9fV8"
      },
      "source": [
        "#preparing the vocabulary for the text\n",
        "TEXT.build_vocab(train_data, min_freq=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9HPCTmUjvvd",
        "outputId": "d128badd-a19f-4ceb-b986-4110f7e3016b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#No. of unique words\n",
        "len(TEXT.vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12483"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BivXzGMDEUMv",
        "outputId": "c4d7b383-60cd-4d0c-d560-20828811fafa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "#word index\n",
        "list(TEXT.vocab.stoi.items())[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<unk>', 0),\n",
              " ('<pad>', 1),\n",
              " ('the', 2),\n",
              " ('i', 3),\n",
              " ('to', 4),\n",
              " ('a', 5),\n",
              " ('of', 6),\n",
              " ('is', 7),\n",
              " ('and', 8),\n",
              " ('in', 9)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjvP5RUw97NX"
      },
      "source": [
        "\n",
        "***Note***: Two special tokens known as unknown and padding will be added to the vocabulary by default\n",
        "\n",
        "* **Unknown token** is used to handle Out Of Vocabulary words. By default, the index of unknown token is 0\n",
        "* **Padding token** is used to make input sequences of same length. By default, the padding token is added at index 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH4Hr9bsHAD-"
      },
      "source": [
        "def fetch_text(examples):\n",
        "\n",
        "  text=[]\n",
        "  for example in examples:\n",
        "    query = vars(example)['query']\n",
        "    text.append(query)\n",
        "    \n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP6tbe1YXhcT"
      },
      "source": [
        "train_text = fetch_text(train_data)\n",
        "valid_text = fetch_text(valid_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCmD_tscB8Tc"
      },
      "source": [
        "def convert2seq(text):\n",
        "  \n",
        "  #padding\n",
        "  text = TEXT.pad(text)\n",
        "  \n",
        "  #converting to numbers\n",
        "  text = TEXT.numericalize(text)\n",
        "  \n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy0jLpHk-gEy"
      },
      "source": [
        "X_train = convert2seq(train_text)\n",
        "X_valid = convert2seq(valid_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9-AU-oUj9Uq",
        "outputId": "fbfb82c4-78f5-4ec1-e082-7d01976b7560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    3,    17,     2,    15,    98,    33,    86,     3,   250,     4,\n",
              "          520,     2,    94,    40,    21,    50,   193,    74,   294,   635,\n",
              "           65,     9, 12271,     3,    17,   266,   283,    78,    26,  2481,\n",
              "         3593,    33,    13,     7,  1877,    12,   103,    21,  2365,  1163,\n",
              "           15,   276,   841,     6,    62,  9865,   460,     0,   460,     0,\n",
              "          460,     0,   460,     0,   460,     0,   927,  4131,   460, 12271,\n",
              "          460,     0,   460,     0,   460,     0,   460,     0,  8616,   286,\n",
              "          286,   286,   286,   286,   286,     0,   460, 10035,   460,   329,\n",
              "            7,    65,  1163,   286,    24,    15,   117,    32,  1374,    66,\n",
              "           65,    69,    70,   598,   681,   104,   681,  1163, 10035,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_kAvrkbP6KU",
        "outputId": "f71f62db-d72d-417c-fb72-676a736f9e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape, X_valid.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8885, 100]), torch.Size([2221, 100]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl_S6Ql2fwjh"
      },
      "source": [
        "def fetch_tags(data):\n",
        "  tags=[]\n",
        "  for example in data.examples:\n",
        "    tags.append(vars(example)['tags'])\n",
        "  return tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L4V-Zdwf1FT"
      },
      "source": [
        "train_tags = fetch_tags(train_data)\n",
        "valid_tags = fetch_tags(valid_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwcyVXZE_1MW",
        "outputId": "60d38cb0-f96c-47a7-fe55-6eeeff2b3286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "train_tags[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['r,logistic',\n",
              " 'machine learning,classification',\n",
              " 'r,time series',\n",
              " 'r,time series',\n",
              " 'probability,distributions']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmT2dgfvOaGw"
      },
      "source": [
        "#preparing the output labels \n",
        "train_tags_list=[i.split(\",\") for i in train_tags]\n",
        "valid_tags_list=[i.split(\",\") for i in valid_tags]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWwlKMXc_R4S",
        "outputId": "58bcf755-5dd2-4ac8-e330-36839e561dd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mlb= MultiLabelBinarizer()\n",
        "mlb.fit(train_tags_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiLabelBinarizer(classes=None, sparse_output=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc4QfBrX_Ryl",
        "outputId": "f4fa0960-0e75-4b45-d36b-b675deb7046d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "mlb.classes_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['classification', 'distributions', 'hypothesis testing',\n",
              "       'logistic', 'machine learning', 'probability', 'r', 'regression',\n",
              "       'self study', 'time series'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6bHhjjsO0oA"
      },
      "source": [
        "y_train  = mlb.transform(train_tags_list)\n",
        "y_valid  = mlb.transform(valid_tags_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbhTziq7O0iT",
        "outputId": "2ec1d43f-a6e9-47b9-bc5b-35bc677878d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape, y_valid.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8885, 10), (2221, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1QdDTe1pKcY",
        "outputId": "138f5745-e16c-4590-d6ec-b3d65241f6de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS0y7u8MQNxf"
      },
      "source": [
        "y_train = torch.FloatTensor(y_train)\n",
        "y_valid = torch.FloatTensor(y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnpswpTgQXuK",
        "outputId": "a842a571-6c9f-458b-a395-d91001139b99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1QO2V5C1q0c"
      },
      "source": [
        "# 4. Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwPA0UEV1sdy"
      },
      "source": [
        " ## 4.1 Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AohYMQDYjf5J"
      },
      "source": [
        "Prior to defining a RNN architecture, we will understand the how RNN layer is defined in pytorch, what are the input and output shapes of an RNN layer in PyTorch\n",
        "\n",
        "As you might remember, preprocessed text data is at first passed through Embedding Layer, then the output of this embedding layer is passed through the RNN layer\n",
        "\n",
        "Lets see what the parameters of Embedding Layer are\n",
        "\n",
        "* **num_embeddings**: Actual feature dimensions of input\n",
        "* **embedding_dim**: Number of embedding dimensions; this is set by the user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-Hu3YNxhx5Z"
      },
      "source": [
        "# define embedding layer\n",
        "emb = Embedding(num_embeddings=len(TEXT.vocab), embedding_dim=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHL606DglJxs",
        "outputId": "1b0a0f55-c120-4657-fe3c-0765d307c816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train[:1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qU_qVYah4sZ"
      },
      "source": [
        "# check sample input\n",
        "sample_embedding = emb(X_train[:1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRqMsYe_jJzW",
        "outputId": "255489bf-7212-4a7e-d20a-a0dfe63f56b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_embedding.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 100, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1nf8tfeInil"
      },
      "source": [
        "In Pytorch, you can easily define RNN layers with same hyperparameters using the RNN module of torch.nn \n",
        "\n",
        "Parameters of RNN layer:\n",
        "\n",
        "* **input_size**: Number of inputs to the RNN\n",
        "* **hidden_size**: Number of neurons in RNN layer.\n",
        "* **batch_first**: Set first dimension to batch size\n",
        "* **nonlinearity**: Activation function on RNN layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GNiEeVSzNqg"
      },
      "source": [
        "#define a rnn\n",
        "rnn = RNN(input_size=50, hidden_size=128, batch_first=True, nonlinearity='relu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWWNM7emrESx"
      },
      "source": [
        "#pass the input to rnn\n",
        "hidden_states,last_hidden_state = rnn(sample_embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2UOiZpIrEOV",
        "outputId": "34d528ff-84e3-4a6a-e206-a8a5239673de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Hidden state of every timestep (Batch, seq_len, no. of hidden neurons)\n",
        "hidden_states.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 100, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X-Sh0Hfsndv",
        "outputId": "16b83da7-f3e5-4d27-f512-eeb9d2b34d09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#output shape of last hidden timestep\n",
        "last_hidden_state.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CR_ZH74oMKU",
        "outputId": "cc1bf7ed-e377-46ad-a8ac-ff2c3b6b2021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#reshaping the hidden states\n",
        "reshaped = hidden_states.reshape(hidden_states.size(0),-1)\n",
        "reshaped.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 12800])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak9rPTehSv0F"
      },
      "source": [
        "# Define Model Architecture\n",
        "\n",
        "# Input\n",
        "# Embedding(embedding_dim=50)\n",
        "# RNN(128)\n",
        "# Linear(128, 'relu')\n",
        "# Linear(10, 'sigmoid')\n",
        "\n",
        "class Net(nn.Module):\n",
        "    \n",
        "    #define all the layers used in model\n",
        "    def __init__(self):\n",
        "        \n",
        "        #Constructor\n",
        "        super(Net, self).__init__()   \n",
        "        \n",
        "        self.rnn_layer = nn.Sequential(\n",
        "            \n",
        "            #embedding layer [batch_size,vocab_size]\n",
        "            Embedding(num_embeddings=len(TEXT.vocab), embedding_dim=50),\n",
        "        \n",
        "            #rnn layer [batch_size,100,128]\n",
        "            RNN(input_size=50, hidden_size=128, nonlinearity='relu',batch_first=True)\n",
        "          \n",
        "            )\n",
        "\n",
        "        self.dense_layer = nn.Sequential(\n",
        "            \n",
        "            #[batch_size,100*128]\n",
        "            Linear(12800, 128),\n",
        "\n",
        "            ReLU(),\n",
        "\n",
        "            #[batch_size,128]\n",
        "            Linear(128,10),\n",
        "            \n",
        "            #[batch_size,10]\n",
        "            Sigmoid()\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        #rnn layer\n",
        "        hidden_states, last_hidden_state = self.rnn_layer(x)\n",
        "\n",
        "        #reshaping\n",
        "        hidden_states = hidden_states.reshape(hidden_states.size(0),-1)\n",
        "\n",
        "        #dense layer\n",
        "        outputs=self.dense_layer(hidden_states)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YJHLpi4Sv5j"
      },
      "source": [
        "#define the model\n",
        "model = Net()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4U_4YfbSv_A",
        "outputId": "fd98f284-3970-427b-e1d1-97ff718468e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "#model layers\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (rnn_layer): Sequential(\n",
              "    (0): Embedding(12483, 50)\n",
              "    (1): RNN(50, 128, batch_first=True)\n",
              "  )\n",
              "  (dense_layer): Sequential(\n",
              "    (0): Linear(in_features=12800, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
              "    (3): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D06A21xv6JaN",
        "outputId": "93573f83-e434-41ed-e00e-b477135152f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#pass an text to the model to understand the output\n",
        "#deactivates autograd\n",
        "with torch.no_grad():\n",
        "  pred = model(X_train[:1])\n",
        "  print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5343, 0.4600, 0.4879, 0.4852, 0.5176, 0.5682, 0.5123, 0.4828, 0.5103,\n",
            "         0.5097]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liHnnKIFjmRj"
      },
      "source": [
        "#define optimizer and loss\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "criterion = BCELoss()\n",
        "\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LleGoa8918PF"
      },
      "source": [
        "## 4.2 Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_v08HY6Sv84"
      },
      "source": [
        "# define training function\n",
        "def train(X,y,batch_size):\n",
        "\n",
        "  #activate training phase\n",
        "  model.train()\n",
        "  \n",
        "  #initialization\n",
        "  epoch_loss= 0\n",
        "  no_of_batches = 0\n",
        "\n",
        "  #randomly create indices\n",
        "  indices= torch.randperm(len(X))\n",
        "  \n",
        "  #loading in batches\n",
        "  for i in range(0,len(indices),batch_size):\n",
        "    \n",
        "    #indices for a batch\n",
        "    ind = indices[i:i+batch_size]\n",
        "  \n",
        "    #batch  \n",
        "    batch_x=X[ind]\n",
        "    batch_y=y[ind]\n",
        "    \n",
        "    #push to cuda\n",
        "    if torch.cuda.is_available():\n",
        "        batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
        "\n",
        "    #clear gradients\n",
        "    optimizer.zero_grad()\n",
        "          \n",
        "    #forward pass\n",
        "    outputs = model(batch_x)\n",
        "\n",
        "    #converting to a 1 dimensional tensor\n",
        "    outputs = outputs.squeeze()\n",
        "\n",
        "    #calculate loss and accuracy\n",
        "    loss = criterion(outputs, batch_y)\n",
        "    \n",
        "    #Backward pass\n",
        "    loss.backward()\n",
        "    \n",
        "    #Update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    #Keep track of the loss and accuracy of a epoch\n",
        "    epoch_loss = epoch_loss + loss.item()\n",
        "\n",
        "    #No. of batches\n",
        "    no_of_batches = no_of_batches+1\n",
        "\n",
        "  return epoch_loss/no_of_batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeCtfkgoSvx8"
      },
      "source": [
        "# define evaluation function\n",
        "def evaluate(X,y,batch_size):\n",
        "\n",
        "  #deactivate training phase\n",
        "  model.eval()\n",
        "\n",
        "  #initialization\n",
        "  epoch_loss = 0\n",
        "  no_of_batches = 0\n",
        "\n",
        "  #randomly create indices\n",
        "  indices= torch.randperm(len(X))\n",
        "\n",
        "  #deactivates autograd\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    #loading in batches\n",
        "    for i in range(0,len(indices),batch_size):\n",
        "      \n",
        "      #indices for a batch\n",
        "      ind = indices[i:i+batch_size]\n",
        "  \n",
        "      #batch  \n",
        "      batch_x= X[ind]\n",
        "      batch_y= y[ind]\n",
        "\n",
        "      #push to cuda\n",
        "      if torch.cuda.is_available():\n",
        "          batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
        "        \n",
        "      #Forward pass\n",
        "      outputs = model(batch_x)\n",
        "\n",
        "      #converting the output to 1 Dimensional tensor\n",
        "      outputs = outputs.squeeze()\n",
        "\n",
        "      # Calculate loss and accuracy\n",
        "      loss = criterion(outputs, batch_y)\n",
        "      \n",
        "      #keep track of loss and accuracy of an epoch\n",
        "      epoch_loss = epoch_loss + loss.item()\n",
        "\n",
        "      #no. of batches\n",
        "      no_of_batches = no_of_batches + 1\n",
        "\n",
        "    return epoch_loss/no_of_batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73CuJpFUYvDM"
      },
      "source": [
        "# define prediction function\n",
        "def predict(X,batch_size):\n",
        "  \n",
        "  #deactivate training phase\n",
        "  model.eval()\n",
        "\n",
        "  # initialization \n",
        "  predictions = []\n",
        "\n",
        "  # create indices\n",
        "  indices = torch.arange(len(X))\n",
        "\n",
        "  #deactivates autograd\n",
        "  with torch.no_grad():\n",
        "      \n",
        "      for i in range(0, len(X), batch_size):\n",
        "        \n",
        "        #indices for a batch\n",
        "        ind = indices[i:i+batch_size]\n",
        "\n",
        "        # batch\n",
        "        batch_x = X[ind]\n",
        "\n",
        "        #push to cuda\n",
        "        if torch.cuda.is_available():\n",
        "            batch_x = batch_x.cuda()\n",
        "\n",
        "        #Forward pass\n",
        "        outputs = model(batch_x)\n",
        "\n",
        "        #converting the output to 1 Dimensional tensor\n",
        "        outputs = outputs.squeeze()\n",
        "\n",
        "        # convert to numpy array\n",
        "        prediction = outputs.data.cpu().numpy()\n",
        "        predictions.append(prediction)\n",
        "    \n",
        "  # convert to single numpy array\n",
        "  predictions = np.concatenate(predictions, axis=0)\n",
        "    \n",
        "  return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5bch29mSve6",
        "outputId": "6a254a0d-360f-4c7d-fc1e-431502210ab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "N_EPOCHS = 10\n",
        "batch_size = 32\n",
        "\n",
        "# intialization\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    #train the model\n",
        "    train_loss   = train(X_train, y_train, batch_size)\n",
        "    \n",
        "    #evaluate the model\n",
        "    valid_loss   = evaluate(X_valid, y_valid, batch_size)\n",
        "\n",
        "    print('\\nEpoch :',epoch,\n",
        "          'Training loss:',round(train_loss,4),\n",
        "          '\\tValidation loss:',round(valid_loss,4))\n",
        "\n",
        "    #save the best model\n",
        "    if best_valid_loss >= valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt') \n",
        "        print(\"\\n----------------------------------------------------Saved best model------------------------------------------------------------------\")   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 0 Training loss: 0.4235 \tValidation loss: 0.3702\n",
            "\n",
            "----------------------------------------------------Saved best model------------------------------------------------------------------\n",
            "\n",
            "Epoch : 1 Training loss: 0.29 \tValidation loss: 0.3337\n",
            "\n",
            "----------------------------------------------------Saved best model------------------------------------------------------------------\n",
            "\n",
            "Epoch : 2 Training loss: 0.1907 \tValidation loss: 0.3631\n",
            "\n",
            "Epoch : 3 Training loss: 0.1023 \tValidation loss: 0.4459\n",
            "\n",
            "Epoch : 4 Training loss: 0.0429 \tValidation loss: 0.5535\n",
            "\n",
            "Epoch : 5 Training loss: 0.0154 \tValidation loss: 0.6735\n",
            "\n",
            "Epoch : 6 Training loss: 0.0052 \tValidation loss: 0.764\n",
            "\n",
            "Epoch : 7 Training loss: 0.0021 \tValidation loss: 0.8268\n",
            "\n",
            "Epoch : 8 Training loss: 0.0012 \tValidation loss: 0.8796\n",
            "\n",
            "Epoch : 9 Training loss: 0.0011 \tValidation loss: 0.9282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPD3sYkO2C8k"
      },
      "source": [
        "# 5. Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45blbQAZ2M8O"
      },
      "source": [
        "## 5.1 Check Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do5YNpepVXE3"
      },
      "source": [
        "Load the best model weights and now, the model is ready for the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gdj5mP2EYZVz",
        "outputId": "9f1565cc-de29-412a-ded7-c399cd1fecea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#load weights of best model\n",
        "path='saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbV0Y8dXYsv2"
      },
      "source": [
        "#predict probabilities\n",
        "y_pred_prob = predict(X_valid, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_K7FERpSvZL",
        "outputId": "62a65ad9-2544-42ed-beab-adedc798abf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "y_pred_prob[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.0765009e-04, 3.4424686e-01, 8.5326970e-02, 1.3579858e-02,\n",
              "       1.0562687e-02, 2.2845514e-01, 4.2070836e-01, 2.7319089e-01,\n",
              "       7.2962564e-01, 4.7954172e-03], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdpKdmTvbEeu"
      },
      "source": [
        "#actual tags\n",
        "y_true = y_valid.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_8v15zo_9D0"
      },
      "source": [
        "The predictions are in terms of probabilities for each of the 10 tags. Hence we need to have a threshold value to convert these probabilities to 0 or 1. Let's specify a set of candidate threshold values. We will select the threshold value that performs the best for the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoyr5wlbSmfI",
        "outputId": "5761ee22-9c53-41f2-9157-fc84b3c261c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "#define candidate threshold values\n",
        "threshold  = np.arange(0,0.5,0.01)\n",
        "print(threshold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.   0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1  0.11 0.12 0.13\n",
            " 0.14 0.15 0.16 0.17 0.18 0.19 0.2  0.21 0.22 0.23 0.24 0.25 0.26 0.27\n",
            " 0.28 0.29 0.3  0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39 0.4  0.41\n",
            " 0.42 0.43 0.44 0.45 0.46 0.47 0.48 0.49]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G39D2TISVhfO"
      },
      "source": [
        "Let's define a function that takes a threshold value and uses it to convert probabilities into 1 or 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvcm8hxPSb3e"
      },
      "source": [
        "# convert probabilities into classes or tags based on a threshold value\n",
        "def classify(y_pred_prob, thresh):\n",
        "  \n",
        "  y_pred = []\n",
        "\n",
        "  for i in y_pred_prob:\n",
        "    temp=[]\n",
        "      \n",
        "    for j in i:\n",
        "      if j>=thresh:\n",
        "        temp.append(1)\n",
        "      else:\n",
        "        temp.append(0)\n",
        "    \n",
        "    y_pred.append(temp)\n",
        "\n",
        "  return np.array(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaH6P-FHhf2Z"
      },
      "source": [
        "We will evaluate the performance of model for each candidate threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG8OFwSuSb0m"
      },
      "source": [
        "score=[]\n",
        "\n",
        "for thresh in threshold:\n",
        "    \n",
        "    #classes for each threshold\n",
        "    y_pred = classify(y_pred_prob, thresh) \n",
        "\n",
        "    #convert to 1d array\n",
        "    y_pred_1d    =  y_pred.ravel()\n",
        "    y_true_1d    =  y_true.ravel()\n",
        " \n",
        "    score.append(metrics.f1_score(y_true_1d, y_pred_1d))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBZxqkmSR_8i",
        "outputId": "98d1ef7b-bbe3-498b-cb4d-ff6bb63f9507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# find the optimal threshold\n",
        "opt = threshold[score.index(max(score))]\n",
        "print(opt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD2l-uNwR7o3"
      },
      "source": [
        "#predictions for optimal threshold\n",
        "y_pred = classify(y_pred_prob, opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdHB_HaJR7m2",
        "outputId": "056e383c-e1e1-410e-e002-d6c21ae5fb8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "#converting to 1D\n",
        "y_pred_1d = y_pred.ravel()\n",
        "\n",
        "#Classification report\n",
        "print(metrics.classification_report(y_true_1d, y_pred_1d))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.91      0.90      0.91     17478\n",
            "         1.0       0.65      0.68      0.66      4732\n",
            "\n",
            "    accuracy                           0.85     22210\n",
            "   macro avg       0.78      0.79      0.78     22210\n",
            "weighted avg       0.86      0.85      0.85     22210\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY-z8S42XTBB",
        "outputId": "d61aa8e6-40e7-415a-ecec-410778c567db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "#convert back to tags\n",
        "y_pred_label = mlb.inverse_transform(np.array(y_pred))\n",
        "y_true_label = mlb.inverse_transform(np.array(y_true))\n",
        "\n",
        "# get all validation text\n",
        "queries = [\" \".join(i) for i in valid_text]\n",
        "\n",
        "# create a dataframe to show the data and prediction side by side\n",
        "df = pd.DataFrame({'Questions':queries,'Actual Tags':y_true_label,'Predicted Tags':y_pred_label})\n",
        "\n",
        "# print first five rows\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "      <th>Actual Tags</th>\n",
              "      <th>Predicted Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>consider the following model y if g x beta u and y otherwise where u is iid according to some distribution function f i want to recover the distribution f without making too many assumptions that ...</td>\n",
              "      <td>(logistic, regression)</td>\n",
              "      <td>(distributions, r, self study)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i am encountering the following problems and i don t really know which model a should pick all model selection criteria indicate that i should take the model with lag after building the var model ...</td>\n",
              "      <td>(hypothesis testing, time series)</td>\n",
              "      <td>(hypothesis testing, regression)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>basically i m attempting to recreate the results of an example from class in r what i m trying to do is decide whether it s best to use a single regression line for an entire data set or two lines...</td>\n",
              "      <td>(r, regression)</td>\n",
              "      <td>(r, regression)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>in general i standardize my independent variables in regressions in order to properly compare the coefficients this way they have the same units standard deviations however with panel longitudinal...</td>\n",
              "      <td>(r, regression)</td>\n",
              "      <td>(r, regression)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>let v to be forecasted value for periods through t and v t be its forecasted value at time t we express v t as the sum of two terms its mean at time t and its deviation from the mean at time t eps...</td>\n",
              "      <td>(r, time series)</td>\n",
              "      <td>(self study, time series)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                 Questions  ...                    Predicted Tags\n",
              "0  consider the following model y if g x beta u and y otherwise where u is iid according to some distribution function f i want to recover the distribution f without making too many assumptions that ...  ...    (distributions, r, self study)\n",
              "1  i am encountering the following problems and i don t really know which model a should pick all model selection criteria indicate that i should take the model with lag after building the var model ...  ...  (hypothesis testing, regression)\n",
              "2  basically i m attempting to recreate the results of an example from class in r what i m trying to do is decide whether it s best to use a single regression line for an entire data set or two lines...  ...                   (r, regression)\n",
              "3  in general i standardize my independent variables in regressions in order to properly compare the coefficients this way they have the same units standard deviations however with panel longitudinal...  ...                   (r, regression)\n",
              "4  let v to be forecasted value for periods through t and v t be its forecasted value at time t we express v t as the sum of two terms its mean at time t and its deviation from the mean at time t eps...  ...         (self study, time series)\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib-fPuHqx2cu"
      },
      "source": [
        "## 5.2 Show Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-xFfFHVdVz5"
      },
      "source": [
        "#raw text\n",
        "text = \"For example, in the case of logistic regression, the learning function is a Sigmoid function that tries to separate the 2 classes\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzCbTh8_dWJa",
        "outputId": "a7cf7231-61e7-49e7-dd10-a8386eb7cdd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#cleaning text\n",
        "tokens = cleaner(text)\n",
        "tokens[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['for', 'example', 'in', 'the', 'case']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqoqyJVtfUbP",
        "outputId": "6bcb5bb0-a3a6-4f78-b598-ce3bdd0dbc51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#first argument to the model is no. of samples\n",
        "tokens = np.array(tokens).reshape(-1,len(tokens))\n",
        "tokens.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tb27oqsdWGH",
        "outputId": "1fd4a3b6-62b7-4bcf-bfa7-7f6a568b37df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "#converting text to integer sequences\n",
        "seq = convert2seq(tokens)\n",
        "seq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  12,  107,    9,    2,  151,    6,   94,   40,    2,  226,   74,    7,\n",
              "            5, 1570,   74,   13, 2927,    4,  960,    2,  373,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c49lZSl4dWDE",
        "outputId": "3966f105-1622-40ce-e0a3-645009c6a538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#predictions\n",
        "with torch.no_grad():\n",
        "  if torch.cuda.is_available():\n",
        "    seq = seq.cuda()\n",
        "  pred_prob= model(seq)\n",
        "  print(pred_prob)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1419, 0.0319, 0.0397, 0.8632, 0.1818, 0.1252, 0.1738, 0.6588, 0.0417,\n",
            "         0.0118]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeH965i2dVud",
        "outputId": "e0b2f20c-ef5b-4339-a8f5-736cf9383587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#classify\n",
        "pred = classify(pred_prob,opt)\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1, 0, 0, 0, 1, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCf__xiIfFU9",
        "outputId": "1bae0353-22af-4494-cbe1-a75b82ab1d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tags  = mlb.inverse_transform(pred)[0]\n",
        "tags"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('logistic', 'regression')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk_3cC8tfFdy"
      },
      "source": [
        "def predict_tags(text):\n",
        "  \n",
        "  tokens = cleaner(text)\n",
        "  \n",
        "  tokens = np.array(tokens).reshape(-1,len(tokens))\n",
        "  \n",
        "  seq = convert2seq(tokens)\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    if torch.cuda.is_available():\n",
        "      seq = seq.cuda()\n",
        "\n",
        "  pred_prob= model(seq)\n",
        "  pred = classify(pred_prob,opt)\n",
        "  \n",
        "  tags  = mlb.inverse_transform(pred)[0]\n",
        "  \n",
        "  return tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0Jxz5kmeyEm",
        "outputId": "dfb7a78d-29a8-4013-88db-8b6cfecc7f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "text = \"For example, in the case of logistic regression, the learning function is a Sigmoid function that tries to separate the 2 classes\"\n",
        "\n",
        "tags = predict_tags(text)\n",
        "print(\"Query: \", text)\n",
        "print(\"Predicted tags:\",tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query:  For example, in the case of logistic regression, the learning function is a Sigmoid function that tries to separate the 2 classes\n",
            "Predicted tags: ('logistic', 'regression')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cN7_48hWIGA"
      },
      "source": [
        "# 6. Model Building for LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVOOA6rFq7jc"
      },
      "source": [
        "In Pytorch, you can easily define LSTM layer using the LSTM module of torch.nn \n",
        "\n",
        "Parameters of LSTM layer:\n",
        "\n",
        "* **input_size**: Number of inputs to the LSTM\n",
        "* **hidden_size**: Number of neurons in LSTM layer.\n",
        "* **batch_first**: Set first dimension to batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QazqtX4Fc-c",
        "outputId": "77e93d30-1182-4b4f-bbbc-3f89573c09e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_embedding.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 100, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQdkmPaPrfXK"
      },
      "source": [
        "#define an LSTM\n",
        "lstm_layer = LSTM(input_size=50, hidden_size=128, batch_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZfiG6PQ-6HI"
      },
      "source": [
        "#pass the input to LSTM\n",
        "hidden_states, (last_hidden_state,last_cell_state) = lstm_layer(sample_embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iipOXzw_Gss",
        "outputId": "855d7ae8-a92e-488d-e184-ed7254515459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Hidden state of every timestep (Batch, seq_len, no. of hidden neurons)\n",
        "hidden_states.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 100, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drJDL9gB_Iq7",
        "outputId": "78d0f9a6-62b2-4872-aafd-a83eb524706d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#output shape of last hidden timestep\n",
        "last_hidden_state.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WB6t5Dl_aoI",
        "outputId": "4beda0f9-7f37-4645-e5cc-8f854e78fb93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#output shape of last cell state\n",
        "last_cell_state.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO_vOTns_KNW",
        "outputId": "10cd6355-f9ce-4ca6-fc0d-6e7941330bcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#reshaping the hidden states\n",
        "reshaped = hidden_states.reshape(hidden_states.size(0),-1)\n",
        "reshaped.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 12800])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pOsmRHSQYuN"
      },
      "source": [
        "# Define Model Architecture\n",
        "\n",
        "# Input\n",
        "# Embedding(embedding_dim=100)\n",
        "# LSTM(128)\n",
        "# Linear(128, 'relu')\n",
        "# Linear(10, 'sigmoid')\n",
        "\n",
        "class Net(nn.Module):\n",
        "    \n",
        "    #Constructor\n",
        "    def __init__(self):\n",
        "\n",
        "        #Constructor\n",
        "        super(Net, self).__init__()   \n",
        "  \n",
        "        #rnn block\n",
        "        self.lstm_layer = Sequential(\n",
        "            \n",
        "            #embedding layer\n",
        "            Embedding(num_embeddings=len(TEXT.vocab), embedding_dim=100),\n",
        "        \n",
        "            #lstm layer\n",
        "            LSTM(input_size=100, hidden_size=128, batch_first=True)\n",
        "          \n",
        "            )\n",
        "\n",
        "        #dense block\n",
        "        self.dense_layer = Sequential(\n",
        "            \n",
        "            Linear(12800,128),\n",
        "\n",
        "            ReLU(),\n",
        "\n",
        "            Linear(128,10),\n",
        "            \n",
        "            Sigmoid()\n",
        "\n",
        "        )\n",
        "    \n",
        "    #forward pass\n",
        "    def forward(self, x):\n",
        "        \n",
        "        #rnn layer\n",
        "        hidden_states, (last_hidden_state,last_cell_state) = self.lstm_layer(x)\n",
        "\n",
        "        #flattening\n",
        "        hidden_states = hidden_states.reshape(hidden_states.size(0),-1)\n",
        "        \n",
        "        #dense layer\n",
        "        outputs=self.dense_layer(hidden_states)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUU13yvgQY1G"
      },
      "source": [
        "#define the model\n",
        "model = Net()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RBtZlDJuu-1",
        "outputId": "b22b08b5-1d36-4784-95fd-adea88063f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "#layers of the model\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (lstm_layer): Sequential(\n",
              "    (0): Embedding(12483, 100)\n",
              "    (1): LSTM(100, 128, batch_first=True)\n",
              "  )\n",
              "  (dense_layer): Sequential(\n",
              "    (0): Linear(in_features=12800, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
              "    (3): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q01g37DbW1n",
        "outputId": "4b76b2a2-fe35-4d7a-d7c1-41ef40ef5d1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#pass an text to the model to understand the output\n",
        "\n",
        "#deactivates autograd\n",
        "with torch.no_grad():\n",
        "  pred = model(X_train[:1])\n",
        "  print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4939, 0.4825, 0.4995, 0.4991, 0.4977, 0.4955, 0.4906, 0.4846, 0.5005,\n",
            "         0.4998]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDxhclMZvUHT"
      },
      "source": [
        "#define optimizer and loss\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "criterion = BCELoss()\n",
        "\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlSsG3LQvUNl",
        "outputId": "c7897532-d1f6-48c0-eb34-b9e5c085ac0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "N_EPOCHS = 10\n",
        "batch_size = 32\n",
        "\n",
        "# intialization\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    #train the model\n",
        "    train_loss   = train(X_train, y_train, batch_size)\n",
        "    \n",
        "    #evaluate the model\n",
        "    valid_loss   = evaluate(X_valid, y_valid, batch_size)\n",
        "\n",
        "    print('\\nEpoch :',epoch,\n",
        "          'Training loss:',round(train_loss,4),\n",
        "          '\\tValidation loss:',round(valid_loss,4))\n",
        "\n",
        "    #save the best model \n",
        "    if best_valid_loss >= valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt') \n",
        "        print(\"\\n----------------------------------------------------Saved best model------------------------------------------------------------------\")   \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 0 Training loss: 0.3733 \tValidation loss: 0.3186\n",
            "\n",
            "----------------------------------------------------Saved best model------------------------------------------------------------------\n",
            "\n",
            "Epoch : 1 Training loss: 0.2379 \tValidation loss: 0.3272\n",
            "\n",
            "Epoch : 2 Training loss: 0.1268 \tValidation loss: 0.3728\n",
            "\n",
            "Epoch : 3 Training loss: 0.0383 \tValidation loss: 0.4867\n",
            "\n",
            "Epoch : 4 Training loss: 0.0103 \tValidation loss: 0.6054\n",
            "\n",
            "Epoch : 5 Training loss: 0.0031 \tValidation loss: 0.6885\n",
            "\n",
            "Epoch : 6 Training loss: 0.0014 \tValidation loss: 0.7525\n",
            "\n",
            "Epoch : 7 Training loss: 0.0009 \tValidation loss: 0.8011\n",
            "\n",
            "Epoch : 8 Training loss: 0.001 \tValidation loss: 0.8371\n",
            "\n",
            "Epoch : 9 Training loss: 0.0005 \tValidation loss: 0.8525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWU2ZDir2q0j"
      },
      "source": [
        "# 7. Model Evaluation for LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYLfWSpqvniv"
      },
      "source": [
        "Load the best model weights and now, the model is ready for the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_jPYFKzvUUq",
        "outputId": "825760d5-ec81-456a-b26d-77b76ea8ef36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#load weights of best model\n",
        "path='saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCLWSfuXQYy9"
      },
      "source": [
        "#predict probabilities\n",
        "y_pred_prob = predict(X_valid, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srL5tr77hAfP",
        "outputId": "186f8c3f-71a1-4314-f46b-02c9a33eed4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "y_pred_prob[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00569856, 0.04902776, 0.09942988, 0.02161415, 0.09411245,\n",
              "       0.04785799, 0.19031535, 0.76762176, 0.50701326, 0.05482058],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0d3ubp2hAdA"
      },
      "source": [
        "score=[]\n",
        "\n",
        "for thresh in threshold:\n",
        "    \n",
        "    #classes for each threshold\n",
        "    y_pred = classify(y_pred_prob, thresh) \n",
        "\n",
        "    #convert to 1d array\n",
        "    y_pred_1d    =  y_pred.ravel()\n",
        "    y_true_1d    =  y_true.ravel()\n",
        " \n",
        "    score.append(metrics.f1_score(y_true_1d, y_pred_1d))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxFk7Gg3hAa8",
        "outputId": "370d1ff4-f36a-4c07-febc-fdf9e62be54f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# find the optimal threshold\n",
        "opt = threshold[score.index(max(score))]\n",
        "print(opt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E8xaA0BhAXy"
      },
      "source": [
        "#predictions for optimal threshold\n",
        "y_pred = classify(y_pred_prob, opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyr-2stWhAVB",
        "outputId": "32298b56-5e97-4585-ed7b-174fa151641e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "#converting to 1D\n",
        "y_pred_1d = y_pred.ravel()\n",
        "\n",
        "#Classification report\n",
        "print(metrics.classification_report(y_true_1d, y_pred_1d))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.91      0.91     17478\n",
            "         1.0       0.67      0.70      0.68      4732\n",
            "\n",
            "    accuracy                           0.86     22210\n",
            "   macro avg       0.79      0.80      0.80     22210\n",
            "weighted avg       0.86      0.86      0.86     22210\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHxsCTdNhAR2"
      },
      "source": [
        "y_pred_label = mlb.inverse_transform(np.array(y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hAUPQFNhAP-"
      },
      "source": [
        "df = pd.DataFrame({'comment':queries,'actual':y_true_label,'predictions':y_pred_label})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd_7LeiDhAM6",
        "outputId": "eb382699-1ead-4849-c779-b06bc56b5913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>actual</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>consider the following model y if g x beta u and y otherwise where u is iid according to some distribution function f i want to recover the distribution f without making too many assumptions that ...</td>\n",
              "      <td>(logistic, regression)</td>\n",
              "      <td>(regression, self study)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i am encountering the following problems and i don t really know which model a should pick all model selection criteria indicate that i should take the model with lag after building the var model ...</td>\n",
              "      <td>(hypothesis testing, time series)</td>\n",
              "      <td>(hypothesis testing, r, regression)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>basically i m attempting to recreate the results of an example from class in r what i m trying to do is decide whether it s best to use a single regression line for an entire data set or two lines...</td>\n",
              "      <td>(r, regression)</td>\n",
              "      <td>(r, regression)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>in general i standardize my independent variables in regressions in order to properly compare the coefficients this way they have the same units standard deviations however with panel longitudinal...</td>\n",
              "      <td>(r, regression)</td>\n",
              "      <td>(r, regression)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>let v to be forecasted value for periods through t and v t be its forecasted value at time t we express v t as the sum of two terms its mean at time t and its deviation from the mean at time t eps...</td>\n",
              "      <td>(r, time series)</td>\n",
              "      <td>(time series,)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                   comment  ...                          predictions\n",
              "0  consider the following model y if g x beta u and y otherwise where u is iid according to some distribution function f i want to recover the distribution f without making too many assumptions that ...  ...             (regression, self study)\n",
              "1  i am encountering the following problems and i don t really know which model a should pick all model selection criteria indicate that i should take the model with lag after building the var model ...  ...  (hypothesis testing, r, regression)\n",
              "2  basically i m attempting to recreate the results of an example from class in r what i m trying to do is decide whether it s best to use a single regression line for an entire data set or two lines...  ...                      (r, regression)\n",
              "3  in general i standardize my independent variables in regressions in order to properly compare the coefficients this way they have the same units standard deviations however with panel longitudinal...  ...                      (r, regression)\n",
              "4  let v to be forecasted value for periods through t and v t be its forecasted value at time t we express v t as the sum of two terms its mean at time t and its deviation from the mean at time t eps...  ...                       (time series,)\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4kI46Z4hAJ8",
        "outputId": "1140576f-2310-4d66-c49b-65dc4d07fb05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "text = \"For example, in the case of logistic regression, the learning function is a Sigmoid function that tries to separate the 2 classes\"\n",
        "\n",
        "tags = predict_tags(text)\n",
        "print(\"Query: \",text)\n",
        "print(\"Predicted tags:\",tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query:  For example, in the case of logistic regression, the learning function is a Sigmoid function that tries to separate the 2 classes\n",
            "Predicted tags: ('logistic', 'r', 'regression')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EASR-WztmqMO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}